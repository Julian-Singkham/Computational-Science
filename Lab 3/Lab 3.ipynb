{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Search Terms with Pandas\n",
    "Submitted By: Julian Singkham  \n",
    "Date: 01/07/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "The purpose of this lab is to familize ourselves with using panda data frames and functional programming for data cleaning, search term analytics, and spellchecking.  \n",
    "* The first objective was to derive search terms from a csv files and clean the data.  \n",
    "* The second objective was to compare the dictionary and list approach of frequency counts to the frequency counts generated by data frame value_counts().\n",
    "\n",
    "The data utilized in this lab is a search term csv file that contains about 1 million search terms used in the Direct Supply DSSI ecommerce platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import pattern.en\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "freq_dict = {}\n",
    "freq_dict_spellchecked = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "\n",
    "\n",
    "Imports a CSV file and creates a dataframe of the first item of each row. Additionally removes web spaces and splits search terms by space.  \n",
    "I.E \"Spicy Bacon\" would be \"Spicy\", \"Bacon\"\n",
    "\n",
    "**Param** csv: Name of the CSV file  \n",
    "**Return**:A data frame of the first item of each row of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_df_first_col(csv):\n",
    "    temp = []\n",
    "    csv_raw_data = []\n",
    "    with open(csv, encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            temp.append(line.rstrip('\\n').split(','))\n",
    "    file.closed\n",
    "    remove_web_spaces_list = [str(row[0]).replace(\"%20\", \" \") for row in temp[1:]]\n",
    "    \n",
    "    split_on_space_list = []\n",
    "    for item in remove_web_spaces_list:\n",
    "        split_on_space_list.extend(item.split(\" \"))\n",
    "        \n",
    "    df = pd.DataFrame({\"Raw Data\" : split_on_space_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a frequency dictionary given a string list where the key is a string and the key-value is how many times the string appeared in the list.\n",
    "\n",
    "**Param** input_list: String list  \n",
    "**Return**: A frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_freq_dict(input_list):\n",
    "    freq_dict = {}\n",
    "    for i in input_list:\n",
    "        freq_dict[i] = input_list.count(i)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a sorted frequency list given a frequency dictionary\n",
    "\n",
    "**Param** freq_dict: Frequnecy dictionary  \n",
    "**Return**: A 2d list where the first row is frequency and the second row is the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq_dict):\n",
    "    sorted_list = [(freq_dict[key], key) for key in freq_dict]\n",
    "    sorted_list.sort()\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a spellchecker dictionary where the key is the misspelled word and the key-value is the most likely corrected word\n",
    "\n",
    "**Param** input_list: List of misspelled words  \n",
    "**Return**: A spellecheck dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_dict_init(input_list):\n",
    "    spell = SpellChecker(distance=1)\n",
    "    spellchecked_dict = {}\n",
    "    for word in input_list:\n",
    "        spellchecked_dict[word] = spell.correction(word)\n",
    "    return spellchecked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a misspelled string token, return the most likely corrected word\n",
    "\n",
    "**Param** token: Misspelled token  \n",
    "**Return**: A correctly spelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_token(token):\n",
    "    fixed_token = ''\n",
    "    if(token != ''):\n",
    "        fixed_token = spellcheck_dict[token]\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(df_x, df_y, lag=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.1 s\n",
      "Wall time: 892 ms\n"
     ]
    }
   ],
   "source": [
    "# Import csv to search term data frame\n",
    "df = import_csv_df_first_col(\"searchTerms.csv\")\n",
    "\n",
    "# This section of code filters the data from the dataset by removing non-alphabet characters, \n",
    "%time df[\"Removed Numbers\"] = df[\"Raw Data\"].str.replace('[0-9]', '')\n",
    "%time df[\"Alphabet Only\"] = df[\"Removed Numbers\"].str.replace('[^a-zA-Z]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Data</th>\n",
       "      <th>Removed Numbers</th>\n",
       "      <th>Alphabet Only</th>\n",
       "      <th>Spellchecked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36969</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500100</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KEND</td>\n",
       "      <td>KEND</td>\n",
       "      <td>KEND</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5750</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>CMED</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>980228</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DYNC1815H</td>\n",
       "      <td>DYNCH</td>\n",
       "      <td>DYNCH</td>\n",
       "      <td>lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DYND70642</td>\n",
       "      <td>DYND</td>\n",
       "      <td>DYND</td>\n",
       "      <td>dyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEES</td>\n",
       "      <td>DEES</td>\n",
       "      <td>DEES</td>\n",
       "      <td>DEES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Raw Data Removed Numbers Alphabet Only Spellchecked\n",
       "0      36969                                           \n",
       "1       CMED            CMED          CMED          med\n",
       "2     500100                                           \n",
       "3       KEND            KEND          KEND          end\n",
       "4       5750                                           \n",
       "5       CMED            CMED          CMED          med\n",
       "6     980228                                           \n",
       "7  DYNC1815H           DYNCH         DYNCH        lynch\n",
       "8  DYND70642            DYND          DYND         dyed\n",
       "9       DEES            DEES          DEES         DEES"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This section of code spellchecks the dataset\n",
    "spellcheck_dict = spellcheck_dict_init(df[\"Alphabet Only\"].tolist())\n",
    "\n",
    "df[\"Spellchecked\"] = df[\"Alphabet Only\"].map(lambda token: spellcheck_token(token))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-1a55f9421d2f>\u001b[0m in \u001b[0;36mlist_to_freq_dict\u001b[1;34m(input_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfreq_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mfreq_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Thia section of code benchmarks the time it takes for the dictionary and list approach to creating a \n",
    "# sorted frequency list of search terms\n",
    "spellcheck_freq_dict = list_to_freq_dict(df[\"Spellchecked\"].tolist())\n",
    "spellcheck_freq_list = sort_freq_dict(spellcheck_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 166 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           165088\n",
       "chicken     18031\n",
       "cream       15222\n",
       "cheese      13344\n",
       "beef        12880\n",
       "juice       10976\n",
       "pie         10943\n",
       "sauce       10686\n",
       "pork        10370\n",
       "potato       9667\n",
       "Name: Spellchecked, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thia section of code benchmarks the time it takes for the data frame approach to creating a \n",
    "# sorted frequency list of search terms\n",
    "%time series_freq = df[\"Spellchecked\"].value_counts(dropna=True)\n",
    "series_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section of code benchmarks the size of the sorted frequency data frame\n",
    "series_freq.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spellcheck_freq_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9bd301eaa668>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This section of code benchmarks the size of the sorted frequency list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspellcheck_freq_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'spellcheck_freq_list' is not defined"
     ]
    }
   ],
   "source": [
    "# This section of code benchmarks the size of the sorted frequency list\n",
    "sys.getsizeof(spellcheck_freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "\n",
    "* The time it took to remove numbers from the dataset took 16ms and 8ms to remove special characeters. The difference in times is attributed to the fact that the dataset used for the second operation is much smaller than the raw dataset. This difference in size allows for faster runtime. The two filtering functions can be done in one command which would take the same amount of time (16ms) as the first filtering function. When compared to the list method (13ms), the time difference between the two is marginal at 3ms which can be attributed to the random nature of time quantum given to threads.  \n",
    "* The time it took to spellcheck the dataset took 954ms while the list method took 795ms. This large difference in time is due to the fact that each column of the dataframe must have the same length, meaning empty values are kept. The dataset given to the list version does not contain empty values. I suspect a separate spellchecked data frame would compute faster than the list version due to the map function with lambda being vectorized.  \n",
    "* The largest difference in timing can be found in the approach to search term frequency. The list method took 1.9s while the data frame approach took  12.5ms. This dramatic difference in timing is due to the highly optimization nature of the pandas library.  \n",
    "* The data frame is about 9x larger at 99,242B when compared to teh 11,512B of the list method. This difference is reasonable as the dataframe data structure contains additional information related to Pandas features, while lists contain raw data.  \n",
    "* Overall the pandas approach used a lot less code due to using functional programming when compared to the list approach. Pandas performance degrades with empty cells and can be slower than a list approach due to the sheer difference in dataset size. One of pandas greatest disadvantage is that each series must be of the same data type, unlike a list which can have muliple data types in rows/cols."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
