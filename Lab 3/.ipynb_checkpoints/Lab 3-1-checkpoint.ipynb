{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Search Terms with Pandas\n",
    "Submitted By: Julian Singkham  \n",
    "Date: 01/07/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "The purpose of this lab is to familize ourselves with using panda data frames and functional programming for data analysis using our own dataset.\n",
    "* The first objective was to derive names from a .txt file that contained rows of data with differing row lengths.\n",
    "* The second objective was to compare the timings and memory used from this dataset to the Direct Supply dataset.\n",
    "\n",
    "The data utilized in this lab is a character names list found in 617 movies by Cornell Movie Dialog Corpus. Due to the nature of name spelling, the filtering of non-alphabet characters and spellchecking was ommitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import pattern.en\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "freq_dict = {}\n",
    "freq_dict_spellchecked = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "\n",
    "\n",
    "Imports the movie_characters_metadata.txt file and creates a data frame of the second item of each row.\n",
    "\n",
    "**Param** None\n",
    "**Return**:A data frame of the second item of each row of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_file_df():\n",
    "    df = pd.read_csv(\"movie_characters_metadata.txt\", delim_whitespace=True, \n",
    "                 names=['a', 'Names', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k'], encoding='iso-8859-1')\n",
    "    return df[\"Names\"].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a frequency dictionary given a string list where the key is a string and the key-value is how many times the string appeared in the list.\n",
    "\n",
    "**Param** input_list: String list  \n",
    "**Return**: A frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_freq_dict(input_list):\n",
    "    freq_dict = {}\n",
    "    for i in input_list:\n",
    "        freq_dict[i] = input_list.count(i)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a sorted frequency list given a frequency dictionary\n",
    "\n",
    "**Param** freq_dict: Frequnecy dictionary  \n",
    "**Return**: A 2d list where the first row is frequency and the second row is the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq_dict):\n",
    "    sorted_list = [(freq_dict[key], key) for key in freq_dict]\n",
    "    sorted_list.sort()\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv to search term data frame\n",
    "df = import_file_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Thia section of code benchmarks the time it takes for the dictionary and list approach to creating a \n",
    "# sorted frequency list of search terms\n",
    "spellcheck_freq_dict = list_to_freq_dict(df[\"Names\"].tolist())\n",
    "spellcheck_freq_list = sort_freq_dict(spellcheck_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MRS.     100\n",
       "MR.       75\n",
       "DR.       75\n",
       "MAN       55\n",
       "WOMAN     39\n",
       "VOICE     39\n",
       "THE       34\n",
       "JACK      33\n",
       "MARY      32\n",
       "FRANK     32\n",
       "Name: Names, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thia section of code benchmarks the time it takes for the data frame approach to creating a \n",
    "# sorted frequency list of search terms\n",
    "%time series_freq = df[\"Names\"].value_counts(dropna=True)\n",
    "series_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311362"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section of code benchmarks the size of the sorted frequency data frame\n",
    "series_freq.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section of code benchmarks the size of the sorted frequency list\n",
    "sys.getsizeof(spellcheck_freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "\n",
    "* Based on the fact that the characters dataset contains 9,035 items while the Direct Supply dataset contains 12,382 items, I believe there will be a linear relation between the two timings (27% faster). This is only valid for the data frame method as the list method does not contain empty values for the Direct Supply dataset. When compared to the list method of the Direct Supply dataset, 1407, the character dataset should take slightly longer to compute due to the time complexity of sort being n*log(n), where the difference in timing plateus very quickly.\n",
    "* In terms of data size, the characters data frame and list should be vastly larger (3-4x) then the Direct Supply data frame due to larger string sizes and higher amount of unique terms. 3.17\n",
    "* The characters dataset data frame method took 6.78ms while the Direct Supply data frame took 3.52ms. I suspect the reason for the this is due to the characters data et having larger string names than the Direct Supply dataset. This difference in word sizes should affect the timing. This difference in size will be discussed in the memory section. The characters dataset list took 3.31s while the Direct Supply dataset list took 2.14s. This difference alligns with my hypothesis and is supported by the difference in memory usage.\n",
    "* The characters dataset data frame used 311,362B of data while the Direct Supply dataset data frame used 99,242B. Allthough I hypothesized the characters dataset would use more memory, I was off by a factor of 2 (4x vs 8x) This vast difference in memory usage surprised me, but after some time made sense as I skimmed the two datasets. I found that the characters dataset had a lot more chars than anticipated. The characters dataset list used 38,208B while the Direct Supply dataset list used 11,512B. This alligns with my inital hypothesis of 3x difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
