{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Search Terms\n",
    "Submitted By: Julian Singkham  \n",
    "Date: 12/18/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "The purpose of this lab is to familize ourselves with data cleaning, search term analytics, and spellchecking.  \n",
    "* The first objective was to derive search terms from a csv files and clean the data.  \n",
    "* The second objective was to create a frequency dictionary of the search terms.  \n",
    "* The final objective was to spellcheck the search terms using spellchecker and create a new spellchecked frequency dictionary\n",
    "\n",
    "The data utilized in this lab is a search term csv file that contains about 1 million search terms used in the direc supply DSSI ecommerce platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "import pattern.en\n",
    "import csv\n",
    "\n",
    "csv_freq_dict = {}\n",
    "csv_freq_dict_spellchecked = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "\n",
    "\n",
    "Imports a CSV file and creates a list of the first item of each row.\n",
    "\n",
    "**Param** csv: Name of the CSV file  \n",
    "**Return**:A list of the first item of each row of the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_list_first_col(csv):\n",
    "    temp = []\n",
    "    csv_raw_data = []\n",
    "    i = 0\n",
    "    with open(csv, encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            if i == 10000:\n",
    "                break\n",
    "            temp.append(line.rstrip('\\n').split(','))\n",
    "            i += 1\n",
    "    csv_raw_data = [str(row[0]) for row in temp]\n",
    "    file.closed\n",
    "    return csv_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of strings, create a new list where each string is split by spaces.  \n",
    "EX: \"Spicy Bacon\" would be [\"spicy\", \"bacon\"]\n",
    "\n",
    "**Param** original_list: List to split  \n",
    "**Return**: A list of single word strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(original_list):\n",
    "    new_list = []\n",
    "    for item in original_list:\n",
    "        new_list.extend(item.split(\" \"))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaces web spaces with a regular space from a string token\n",
    "\n",
    "**Param** token: String token  \n",
    "**Return**: A string without web spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_web_spaces(token):\n",
    "    token.replace(\"%20\", \" \")\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes non-alphabet characters from a string token\n",
    "\n",
    "**Param** token: String token  \n",
    "**Return**: A string with only alphabet characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabet(token):\n",
    "    fixed_token = \"\"\n",
    "    for char in token:\n",
    "        if char.isalpha() or char == \" \":\n",
    "            fixed_token = fixed_token + char\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a frequency dictionary given a string list where the key is a string and the key-value is how many times the string appeared in the list.\n",
    "\n",
    "**Param** input_list: String list  \n",
    "**Return**: A frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_freq_dict(input_list):\n",
    "    freq_dict = {}\n",
    "    for i in input_list:\n",
    "        freq_dict[i] = input_list.count(i)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a sorted frequency list given a frequency dictionary\n",
    "\n",
    "**Param** freq_dict: Frequnecy dictionary  \n",
    "**Return**: A 2d list where the first row is frequency and the second row is the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_freq_dict(freq_dict):\n",
    "    sorted_list = [(freq_dict[key], key) for key in freq_dict]\n",
    "    sorted_list.sort()\n",
    "    sorted_list.reverse()\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a spellchecker dictionary where the key is the misspelled word and the key-value is the most likely corrected word\n",
    "\n",
    "**Param** input_list: List of misspelled words  \n",
    "**Return**: A spellecheck dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_dict_init(input_list):\n",
    "    spell = SpellChecker(distance=1)\n",
    "    spellchecked_dict = {}\n",
    "    for word in input_list:\n",
    "        spellchecked_dict[word] = spell.correction(word)\n",
    "    return spellchecked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a misspelled string token, return the most likely corrected word\n",
    "\n",
    "**Param** token: Misspelled token  \n",
    "**Return**: A correctly spelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcheck_token(token):\n",
    "    fixed_token = csv_spellcheck_dict[token]\n",
    "    return fixed_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a csv file from a frequency list\n",
    "\n",
    "**Param** input_list: Frequency list  \n",
    "**Return**: NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_csv(input_list):\n",
    "    fields = [\"Frequency\", \"Word\"]\n",
    "    with open(\"Frequency of search terms.csv\", \"w\", newline=\"\") as file:\n",
    "        write = csv.writer(file)\n",
    "        write.writerow(fields)\n",
    "        write.writerows(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.97 ms\n"
     ]
    }
   ],
   "source": [
    "# Import csv to search term list\n",
    "%time csv_raw = import_csv_list_first_col(\"searchTerms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This section of code filters the data from the csv file by removing non-alphabet characters, \n",
    "# replacing web spaces with spaces, and splitting search terms by word\n",
    "\n",
    "csv_filtered = []\n",
    "for i in range(len(csv_raw)):\n",
    "    temp = remove_non_alphabet(remove_web_spaces(csv_raw[i]))\n",
    "    csv_filtered.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%time csv_filtered = split_tokens(csv_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# This section removes all blank search terms. Blank search terms are generated from the above section of code\n",
    "# due to the removal of non-alphabet characters.\n",
    "csv_fixed = []\n",
    "for word in csv_filtered:\n",
    "    if len(word) != 0:\n",
    "        csv_fixed.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.23 s\n",
      "Wall time: 994 Âµs\n"
     ]
    }
   ],
   "source": [
    "# This section of code creates a frequency dictionary of the filtered data.\n",
    "# A list is also created to sort the frequency dictionary from most frequent to least.\n",
    "%time csv_freq_dict = list_to_freq_dict(csv_fixed)\n",
    "%time csv_freq_list = sort_freq_dict(csv_freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 795 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This section of code creates a spellchecked version of the fully filtered search terms list.\n",
    "# Additionally it creates a frequency dictionary and a sorted list of the most frequent to least\n",
    "csv_spellcheck_dict = spellcheck_dict_init(csv_fixed)\n",
    "csv_spellchecked = []\n",
    "for word in csv_fixed:\n",
    "    csv_spellchecked.append(spellcheck_token(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.13 s\n",
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time csv_spellcheck_dict = list_to_freq_dict(csv_spellchecked)\n",
    "%time csv_spellcheck_freq_list = sort_freq_dict(csv_spellcheck_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "# Creates a csv file of the spellchecked search term frequency list from most frequent to least\n",
    "%time list_to_csv(csv_spellcheck_freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "* The most frequent search tokens for the non-spellchecked data is food items like bacon, milk, chicken, beef. Bacon by far has the most hits with 459, followed by milk at 180 and chicken at 168. This is most likely due to the American breakfast having bacon as one of its components, additionally bacon is the most enjoyed bacon item so this makes sense. Food being the primarily searched items is logical as humans require a large amount of food on a daily basis.  \n",
    "* I hypothesis that numerical only entries are the UIC of the desired product. This would make sense as if I were to look up bacon there would be several different types one could buy, by using the specific UIC of the desired bacon, only one item pops up. Special characters could be search operators such as \"XXX\" being used to specify that the item must contain XXX in the name. \"-XXX\" could be used to specify that the item must not contain XXX.\n",
    "*  The spellchecked data in comparison to the original for the most part is the same. Some items saw a slight increase in frequency such as Juice increasing from 131 to 132 when using the spellchecked data. This isn't a surprise as people for the most part can correctly type the name of an item, I hypothesize that the more complex terms will see a much higher increase in hits due to the nature of the spelling.\n",
    "* Overall I believe the spellchecked data is more accurate than the non-spellchecked version, but the magnitude is relatively small. The accuracy is in part due to most misspellings only containing one error and the spellchecker has relatively high accuracy in its spelling preditcion. As stated before most people should be able to spell words at a high level of accuracy so the only search terms that would benefit from spellchecker are edgecase complex ones. One issue with spellchecking is that the spellchecked version may be incorrect due to spelling properties such as spelling potatoe. The plural form of potato is potatoes so it can be assumed the user forgot an s rather than accidently added e to the word.\n",
    "* The longest runing method is the list_to_freq_dict due to the count() method iterating through each item in the list. This is an O(n^2) operation due to each element in the list iterating through the entire list. If the list is 10x bigger it would take 100 times longer and at 100x it would take 10000 times longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "(1) Used the information in this link for removing non alphabet characters.\n",
    "https://stackoverflow.com/questions/43023795/removing-all-numeric-characters-in-a-string-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
